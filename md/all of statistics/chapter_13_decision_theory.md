# Chapter 13: Statistical Decision Theory - Mathematical Explanations

## Overview
Statistical decision theory provides a unified framework for making optimal decisions under uncertainty. It formalizes how to choose actions based on data when the consequences of decisions depend on unknown parameters, connecting statistics with economics, game theory, and optimization.

## 13.1 Elements of Decision Theory

### Basic Framework
A **statistical decision problem** consists of:

1. **Parameter space** Œò: Set of possible states of nature
2. **Action space** ùíú: Set of possible actions/decisions  
3. **Sample space** ùí≥: Set of possible observations
4. **Loss function** L(Œ∏, a): Cost of taking action a when true parameter is Œ∏
5. **Statistical model** {P_Œ∏ : Œ∏ ‚àà Œò}: Family of distributions for data

### Decision Rules
A **decision rule** Œ¥ is a function that maps observations to actions:
```
Œ¥: ùí≥ ‚Üí ùíú
```

For observed data x, we take action Œ¥(x).

### Randomized Decision Rules
A **randomized decision rule** Œ¥ maps observations to probability distributions over actions:
```
Œ¥: ùí≥ ‚Üí ‚Ñ≥(ùíú)
```

where ‚Ñ≥(ùíú) is the set of probability measures on ùíú.

## 13.2 Loss Functions and Risk

### Common Loss Functions

**Squared error loss:** L(Œ∏, a) = (Œ∏ - a)¬≤
- Used for estimation problems
- Penalizes large errors heavily

**Absolute error loss:** L(Œ∏, a) = |Œ∏ - a|
- More robust to outliers
- Leads to median as optimal estimator

**0-1 loss:** L(Œ∏, a) = I(Œ∏ ‚â† a)
- Used for classification/testing
- All errors weighted equally

**Asymmetric loss:** Different penalties for over/under-estimation
```
L(Œ∏, a) = \begin{cases}
c‚ÇÅ(Œ∏ - a) & \text{if } a < Œ∏ \\
c‚ÇÇ(a - Œ∏) & \text{if } a ‚â• Œ∏
\end{cases}
```

### Risk Function
The **risk** of decision rule Œ¥ is:
```
R(Œ∏, Œ¥) = E_Œ∏[L(Œ∏, Œ¥(X))] = \int L(Œ∏, Œ¥(x)) dP_Œ∏(x)
```

**Interpretation:** Expected loss when true parameter is Œ∏ and we use rule Œ¥.

### Examples

**Point estimation:** 
- Action space: ùíú = Œò (estimate the parameter)
- Common loss: L(Œ∏, a) = (Œ∏ - a)¬≤
- Risk: R(Œ∏, Œ¥) = E_Œ∏[(Œ∏ - Œ¥(X))¬≤] = MSE

**Hypothesis testing:**
- Action space: ùíú = {0, 1} (reject/accept H‚ÇÄ)
- 0-1 loss: L(Œ∏, a) = I(wrong decision)
- Risk: R(Œ∏, Œ¥) = P_Œ∏(wrong decision)

## 13.3 Comparing Decision Rules

### Dominance
Decision rule Œ¥‚ÇÅ **dominates** Œ¥‚ÇÇ if:
```
R(Œ∏, Œ¥‚ÇÅ) ‚â§ R(Œ∏, Œ¥‚ÇÇ) for all Œ∏ ‚àà Œò
```

with strict inequality for at least one Œ∏.

**Admissible rule:** Not dominated by any other rule.
**Inadmissible rule:** Dominated by some other rule.

### Complete Class
A class C of decision rules is **complete** if for every rule Œ¥ ‚àâ C, there exists Œ¥' ‚àà C such that Œ¥' dominates Œ¥.

**Minimal complete class:** Complete class with no proper complete subset.

### Optimal Rules
**Problem:** Generally no single rule dominates all others.

**Solutions:**
1. Restrict attention to specific criteria
2. Average over prior distribution (Bayesian)
3. Consider worst-case scenario (minimax)

## 13.4 Bayesian Decision Theory

### Prior Distribution
Assume parameter Œ∏ has **prior distribution** œÄ(Œ∏) representing beliefs before seeing data.

### Posterior Distribution
After observing data x, update beliefs using Bayes' theorem:
```
œÄ(Œ∏|x) = \frac{f(x|Œ∏)œÄ(Œ∏)}{m(x)}
```

where m(x) = ‚à´ f(x|Œ∏)œÄ(Œ∏) dŒ∏ is marginal likelihood.

### Posterior Risk
For given data x, the **posterior risk** of action a is:
```
œÅ(a|x) = E[L(Œ∏, a)|x] = \int L(Œ∏, a) œÄ(Œ∏|x) dŒ∏
```

### Bayes Action
The **Bayes action** minimizes posterior risk:
```
a*(x) = \argmin_a œÅ(a|x)
```

### Bayes Risk
The **Bayes risk** of decision rule Œ¥ is:
```
r(œÄ, Œ¥) = E_œÄ[R(Œ∏, Œ¥)] = \int R(Œ∏, Œ¥) œÄ(Œ∏) dŒ∏
```

**Bayes rule:** Decision rule Œ¥_œÄ that minimizes Bayes risk:
```
Œ¥_œÄ = \argmin_Œ¥ r(œÄ, Œ¥)
```

### Examples

**Point estimation under squared error:**
- Posterior risk: œÅ(a|x) = E[(Œ∏ - a)¬≤|x]
- Bayes action: a*(x) = E[Œ∏|x] (posterior mean)

**Point estimation under absolute error:**
- Bayes action: a*(x) = median of œÄ(Œ∏|x)

**Hypothesis testing:**
- H‚ÇÄ: Œ∏ ‚àà Œò‚ÇÄ vs H‚ÇÅ: Œ∏ ‚àà Œò‚ÇÅ
- 0-1 loss with costs c‚ÇÄ, c‚ÇÅ
- Bayes action: Choose H‚ÇÅ if P(Œ∏ ‚àà Œò‚ÇÅ|x) > c‚ÇÄ/(c‚ÇÄ + c‚ÇÅ)

## 13.5 Minimax Decision Theory

### Minimax Criterion
When no prior information available, consider worst-case scenario.

**Minimax rule:** Minimizes maximum risk:
```
Œ¥_M = \argmin_Œ¥ \sup_Œ∏ R(Œ∏, Œ¥)
```

**Minimax risk:**
```
R_M = \inf_Œ¥ \sup_Œ∏ R(Œ∏, Œ¥)
```

### Least Favorable Prior
Prior œÄ* is **least favorable** if:
```
\sup_œÄ \inf_Œ¥ r(œÄ, Œ¥) = \inf_Œ¥ r(œÄ*, Œ¥)
```

**Connection to minimax:** Under regularity conditions, minimax rule equals Bayes rule for least favorable prior.

### Examples

**Normal mean estimation:**
- X ~ N(Œ∏, 1), squared error loss
- Minimax estimator: Œ¥_M(x) = x (sample mean)
- Minimax risk: R_M = 1

**Bernoulli parameter estimation:**
- X ~ Binomial(n, Œ∏), squared error loss  
- Minimax estimator: Œ¥_M(x) = (x + ‚àön/2)/(n + ‚àön)

## 13.6 Admissibility

### Characterizing Admissible Rules
**Theorem:** If Œ¥ is a unique Bayes rule for some prior œÄ, then Œ¥ is admissible.

**Theorem:** If Œ¥ is a limit of Bayes rules and has finite risk, then Œ¥ is admissible.

### Complete Class Theorems
**Theorem:** Under mild conditions, the class of all Bayes rules forms a complete class.

**Corollary:** Admissible rules are either Bayes rules or limits of Bayes rules.

### Examples of Inadmissible Estimators

**Stein's phenomenon:** For Œ∏ ‚àà ‚Ñù·µñ with p ‚â• 3:
- MLE Œ∏ÃÇ = X is inadmissible under squared error loss
- James-Stein estimator dominates MLE:
  ```
  Œ¥_JS(X) = (1 - (p-2)/||X||¬≤)X
  ```

**Baseball batting averages:** Stein's insight applied to predicting performance.

## 13.7 Invariance

### Group Actions
A **group** G acts on parameter space Œò and sample space ùí≥.

**Invariant decision problem:** Loss function satisfies:
```
L(gŒ∏, ga) = L(Œ∏, a) for all g ‚àà G
```

### Invariant Decision Rules
Rule Œ¥ is **invariant** if:
```
Œ¥(gx) = gŒ¥(x) for all g ‚àà G
```

### Principle of Invariance
**Principle:** When decision problem has invariance structure, restrict attention to invariant rules.

**Justification:** If non-invariant rule Œ¥ is optimal, then orbit average of Œ¥ is also optimal and invariant.

### Hunt-Stein Theorem
Under certain conditions, best invariant rule is minimax among all rules.

### Examples

**Location parameter:** X = Œ∏ + Œµ where Œµ ~ F
- Group: G = {translations}
- Invariant estimators: Œ¥(x) = x + c for constant c
- Under squared error: c = 0, so Œ¥(x) = x

**Scale parameter:** X = Œ∏Œµ where Œµ ~ F  
- Group: G = {scalings}
- Invariant estimators: Œ¥(x) = cx for constant c

## 13.8 Empirical Bayes

### Setup
Assume Œ∏ ~ G (unknown prior) and X|Œ∏ ~ F(¬∑|Œ∏).

**Goal:** Estimate Œ∏ based on X without knowing G.

### Empirical Bayes Approach
1. Estimate prior G from marginal distribution of X
2. Use estimated prior in Bayes rule

### Parametric Empirical Bayes
Assume G belongs to parametric family G_Œ±.

**Two-stage procedure:**
1. Estimate Œ± from marginal likelihood
2. Use G_Œ±ÃÇ as prior in Bayes rule

### Nonparametric Empirical Bayes
Estimate G nonparametrically from marginal distribution.

**Example (Robbins):** For Poisson model:
- X|Œ∏ ~ Poisson(Œ∏), Œ∏ ~ G
- Bayes estimator: E[Œ∏|X = x] = (x+1)f(x+1)/f(x)
- Empirical Bayes: Replace f with empirical probabilities

### Asymptotic Properties
**Theorem:** Under regularity conditions, empirical Bayes risk approaches Bayes risk as sample size increases.

## 13.9 Sequential Decision Theory

### Sequential Sampling
At each stage, decide whether to:
1. **Stop** and make terminal decision
2. **Continue** and take another observation

### Optimal Stopping
**Value function:** V(x) = expected future payoff starting from state x

**Bellman equation:**
```
V(x) = \max{\text{stop value}, \text{continuation value}}
```

### Sequential Probability Ratio Test (SPRT)
**Problem:** Test H‚ÇÄ: Œ∏ = Œ∏‚ÇÄ vs H‚ÇÅ: Œ∏ = Œ∏‚ÇÅ

**Likelihood ratio:** Œõ‚Çô = ‚àè·µ¢‚Çå‚ÇÅ‚Åø f(X·µ¢|Œ∏‚ÇÅ)/f(X·µ¢|Œ∏‚ÇÄ)

**Decision rule:**
- If Œõ‚Çô ‚â• B: reject H‚ÇÄ
- If Œõ‚Çô ‚â§ A: accept H‚ÇÄ  
- If A < Œõ‚Çô < B: continue sampling

**Optimality:** SPRT minimizes expected sample size among all tests with given error probabilities.

### Multi-armed Bandits
**Setup:** K arms, each with unknown reward distribution

**Goal:** Maximize total reward over T periods

**Explore vs exploit dilemma:**
- **Exploration:** Try different arms to learn rewards
- **Exploitation:** Choose best-known arm

**UCB algorithm:** Choose arm with highest upper confidence bound
**Thompson sampling:** Choose arm randomly based on posterior probabilities

## 13.10 Game Theory Connections

### Two-Person Zero-Sum Games
**Players:** Statistician (chooses Œ¥) vs Nature (chooses Œ∏)
**Payoff:** -R(Œ∏, Œ¥) to statistician

**Minimax theorem:** Under mild conditions:
```
\inf_Œ¥ \sup_Œ∏ R(Œ∏, Œ¥) = \sup_œÄ \inf_Œ¥ r(œÄ, Œ¥)
```

### Mixed Strategies
**Statistician's mixed strategy:** Randomized decision rule
**Nature's mixed strategy:** Prior distribution on Œ∏

### Nash Equilibrium
**Definition:** Strategy profile where no player can improve by unilateral deviation

**Connection:** Minimax strategies form Nash equilibrium.

## 13.11 Information Theory and Decision Theory

### Mutual Information
**Definition:** I(X; Œ∏) = H(Œ∏) - H(Œ∏|X)

**Interpretation:** Expected reduction in uncertainty about Œ∏ after observing X.

### Value of Information
**Expected value of sample information:**
```
EVSI = r(œÄ, Œ¥‚ÇÄ) - r(œÄ, Œ¥*)
```

where Œ¥‚ÇÄ is optimal action without data, Œ¥* is Bayes rule.

### Information and Risk
**General principle:** More informative experiments lead to better decisions (lower Bayes risk).

## 13.12 Robust Decision Theory

### Model Uncertainty
**Problem:** True model may not be in assumed class.

**Œì-minimax:** Minimize maximum risk over class Œì of possible models:
```
\inf_Œ¥ \sup_{P \in Œì} R_P(Œ¥)
```

### Contamination Models
**Œµ-contamination:** True distribution in {(1-Œµ)F + ŒµG : G ‚àà ùí¢}

**Robust Bayes:** Use least favorable prior within contamination class.

### Sensitivity Analysis
Study how Bayes decisions change with prior specification:
- **Prior robustness:** Range of priors leading to same decision
- **Posterior robustness:** How much data needed to overcome prior

## 13.13 Computational Aspects

### Numerical Integration
Bayesian decisions often require computing:
```
\int L(Œ∏, a) œÄ(Œ∏|x) dŒ∏
```

**Methods:**
- Quadrature rules
- Monte Carlo integration
- Importance sampling

### MCMC for Decision Theory
**Gibbs sampling:** Sample from posterior œÄ(Œ∏|x)
**Metropolis-Hastings:** General MCMC for complex posteriors

**Decision making:** Use MCMC samples to approximate posterior risk.

### Approximation Methods
**Laplace approximation:** Approximate posterior with normal distribution
**Variational Bayes:** Optimize over simpler family of distributions

## 13.14 Multiple Decision Problems

### Simultaneous Inference
**Problem:** Make K decisions simultaneously
**Loss:** L(Œ∏, a‚ÇÅ, ..., a‚Çñ) for joint actions

**Compound decisions:** Many similar problems
**Empirical Bayes approach:** Learn from similar problems

### False Discovery Rate
**Multiple testing:** Control expected proportion of false discoveries
**Connection to decision theory:** FDR procedures are Bayes rules under specific loss functions

### Hierarchical Models
**Structure:** Œ∏·µ¢ ~ G, X·µ¢|Œ∏·µ¢ ~ F(¬∑|Œ∏·µ¢)
**Shrinkage:** Individual estimates pulled toward group mean

## 13.15 Applications

### Medical Diagnosis
**Elements:**
- Œ∏: Disease state
- X: Test results  
- A: Treatment decisions
- L: Cost of incorrect treatment

**ROC analysis:** Trade-off between sensitivity and specificity

### Quality Control
**Process monitoring:** Decide when to adjust/stop process
**Sequential sampling:** Continue monitoring vs take action

### Portfolio Optimization
**Mean-variance framework:** Balance expected return vs risk
**Bayesian portfolio:** Incorporate parameter uncertainty

### Clinical Trials
**Adaptive designs:** Modify trial based on interim results
**Stopping rules:** Balance statistical power vs patient welfare

## 13.16 Asymptotic Decision Theory

### Large Sample Behavior
**Asymptotic risk:** lim_{n‚Üí